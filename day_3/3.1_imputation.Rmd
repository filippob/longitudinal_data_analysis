---
title: 'Imputation of missing data'
author: "Nelson Nazzicari"
date: "2024-11-07"
output: html_document
---

```{r setup, include=FALSE}
# library("DT")
# library("broom")
# library("knitr")
# library("ggpubr")
# library("contrast")
# library("tidyverse")
library("data.table")
library(plyr)

knitr::opts_chunk$set(echo = TRUE)
```


## Read the data

Data from [The early bird gets the worm: foraging strategies of wild songbirds lead to the early discovery of food sources](https://royalsocietypublishing.org/doi/10.1098/rsbl.2013.0578)
(data repo [here](https://zenodo.org/record/4936819))

It's data on time needed to discover food sources in songbirds.

```{r read-the-bird-data}
basefolder = "/home/filippo/Dropbox/cursos/longitudinal_data_analysis/longitudinal_data_analysis"
basefolder = "~/research/longitudinal_data_analysis"
inpfile = "../data/bird_food/discovery_individuals.csv"
fname = file.path(basefolder, inpfile)

birds = fread(inpfile)
```

Dataset on wild songbirds and their foraging habits (from here: "The early bird gets the worm", https://zenodo.org/record/4936819).

The target variable is *time to discovery* (of food: continuous, in seconds).
Explanatory variables include:

- `TREATMENT`: morning / afternoon
- `HALFHOUR`: time during the day
- `SITE`: geographic place
- `WEEK`: replicates over two weeks


We can consider *week* to be a replicate of the experiment (two different weeks, like two random replicates),
and we can combine the part of the day (morning/afternoon) and half hour to have a unique expression of the time of the day.

This will lead to the following model.

$$
\text{TIME.TO.DISC} = \mu + time + \beta_1 \text{time} + \beta_2 \text{SITE} + e
$$

## Helper functions

```{r helper_functions}
inject_missing_datapoints = function(x, fraction = 0.1){
  #how many actual missing points we'll have
  n = length(x) * fraction
  
  #sampling that many 
  holes = sample(1:length(x), size=n, replace=FALSE)
  
  #and we are done
  x[holes] = NA
  return(x)
}

RMSE = function(y, yhat){
  res = (y - yhat) ^ 2
  res = sqrt(mean(res))
  return(res)
}
```

### RFi - a simple implementation

We are going to inject a 10% of missing data point, impute with RFi, and evaluate the error rate

```{r}
MISSING_RATE = 0.1

#the dataset with missing elements
birds_missing = birds
birds_missing$TIME.TO.DISC. = inject_missing_datapoints(x = birds_missing$TIME.TO.DISC., fraction = MISSING_RATE)

#plotting 
plot(birds$TIME.TO.DISC., xlab='', ylab='Time to discovery')
points(birds_missing$TIME.TO.DISC., pch=4, col='red')

#a little interface printing
print(paste('Number of samples:', nrow(birds)))
print(paste('Number of missing values:', sum(is.na(birds_missing$TIME.TO.DISC.))))
```

```{r}
#actual imputation
library(missForest)

#a little type wrangling: character columns are not welcome by missForest. Either
#change it to numeric or, in our case, factors
birds_missing$TAG = as.factor(birds_missing$TAG)
birds_missing$SITE = as.factor(birds_missing$SITE)
birds_missing$TREATMENT = as.factor(birds_missing$TREATMENT)

#too many tags...
birds_missing$TAG = NULL

#imputing. Of the output we focus on the $ximp field, which is our old matrix, but
#imputed
birds_imputed = missForest(birds_missing)$ximp

#plotting only missing and imputed values
sel = is.na(birds_missing$TIME.TO.DISC.)
plot(birds[sel]$TIME.TO.DISC., xlab='', ylab='Time to discovery', main='True (o) vs imputed (*)')
points(birds_imputed[sel]$TIME.TO.DISC., pch=8, col='blue')

#evaluating the RMSE
RMSE(y=birds$TIME.TO.DISC., yhat = birds_imputed$TIME.TO.DISC.)
```

### A more systematic evaluation

We want to test RFi:

- over a few repetitions, so that we don't depend on specific missing samples
- over a range of injected data, so to have an idea of when missing rate becomes too much 

```{r}
REPETITIONS = 10
MISSING_RATES = c(0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.50, 0.70)

res = NULL

for (rep in 1:REPETITIONS){
  for (mr in MISSING_RATES){
    #preparing the dataset
    birds_missing = birds
    birds_missing$TIME.TO.DISC. = inject_missing_datapoints(x = birds_missing$TIME.TO.DISC., fraction = mr)
    birds_missing$SITE = as.factor(birds_missing$SITE)
    birds_missing$TREATMENT = as.factor(birds_missing$TREATMENT)
    birds_missing$TAG = NULL

    #imputing
    birds_imputed = missForest(birds_missing)$ximp

    #computing RMSE
    error = RMSE(y=birds$TIME.TO.DISC., yhat = birds_imputed$TIME.TO.DISC.)
      
    #taking notes of the result
    res = rbind(res, data.frame(
      algorithm = 'RFi',
      missing_rate = mr,
      RMSE = error 
    ))
  }
}

#averaging over repetitions
res_m = ddply(res, .(algorithm, missing_rate), function(x){
  return(data.frame(RMSE = mean(x$RMSE)))
})

plot(res_m[,c('missing_rate', 'RMSE')], type='b')

```

### Go faster with parallel execution

Imputing the same dataset, a few times, to have an idea about time improvement
due to parallel execution



```{r}
#non-parallel execution
start_time = Sys.time()
for (i in 1:10){
     birds_imputed = missForest(birds_missing)$ximp
}
stop_time = Sys.time()
print(stop_time - start_time)
```

```{r message=FALSE}
#parallel execution
doParallel::registerDoParallel(cores=4)
start_time = Sys.time()
for (i in 1:10){
     birds_imputed = missForest(birds_missing, parallelize = 'forest')$ximp
}
stop_time = Sys.time()
print(stop_time - start_time)
```

Uh-oh...

