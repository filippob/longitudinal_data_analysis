{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Block cross validation\n",
        "\n",
        "After covering random cross-validation, we now introduce a more advanced topic: cross-validation for data with temporal, spatial, hierarchical or phylogenetic structure (stratified data).\n",
        "\n",
        "We are using the same dataset on fish catch."
      ],
      "metadata": {
        "id": "E-AJGZ6FqW_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "f6_nu99esFyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Read data\n",
        "\n",
        "Data from [Spatiotemporally explicit model averaging for forecasting of Alaskan groundfish catch](https://onlinelibrary.wiley.com/doi/10.1002/ece3.4488) (data repo [here](https://zenodo.org/record/4987796#.ZHcLL9JBxhE))\n",
        "\n",
        "It's data on fish catch (multiple fish species) over time in different regions of Alaska."
      ],
      "metadata": {
        "id": "-YUAvMpSr7Bf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hATDEqJTqOjC"
      },
      "outputs": [],
      "source": [
        "url= \"https://zenodo.org/records/4987796/files/stema_data.csv\"\n",
        "fish = pd.read_csv(url)\n",
        "fish.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing\n",
        "\n",
        "-   `V1` is record ID\n",
        "-   `Station` indicates the fishing station\n",
        "\n",
        "We will not consider these variables in the predictive model.\n",
        "\n",
        "In order to accommodate variation in SST among stations, the CPUE value has been replicated multiple times. This would defeat our purpose of analysing data by group (fish species) over space and time: with only one value per group, a statistical analysis is a bit hard to be performed (no variation). Therefore, to the original CPUE values we add some random noise proportional to the average (by species, area, year):"
      ],
      "metadata": {
        "id": "oJkEiaVrsBPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish = fish.drop(['Unnamed: 0', 'Latitude', 'Longitude', 'Station'], axis=1)"
      ],
      "metadata": {
        "id": "7gJjzNJksBy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## mutate variable\n",
        "fish['avg'] = fish.groupby(['Species', 'Area', 'Year'])['CPUE'].transform('mean')\n",
        "fish['std'] = 0.1 * fish['avg']"
      ],
      "metadata": {
        "id": "4sojDKLzse7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fish['noise'] = np.random.normal(loc=0, scale=fish['std'])\n",
        "fish['CPUE'] = fish['CPUE'] + fish['noise']"
      ],
      "metadata": {
        "id": "SrWI3KlWshM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fish = fish.drop(['avg', 'std', 'noise'], axis=1)"
      ],
      "metadata": {
        "id": "ivLIId7jsjCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## sanity check!\n",
        "fish.head()"
      ],
      "metadata": {
        "id": "EMRlatDbsk6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We prepare the arrays for the linear model:"
      ],
      "metadata": {
        "id": "FoAto3n2swJS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Block validation strategies\n",
        "\n",
        "We first block by time (longitudinal data), using the variable `Year`:\n",
        "\n",
        "### 1. Define the data split\n",
        "\n",
        "We order data by Year: data are balanced, there are 292 records per year. The last 4 Years of data therefore represent 17.39% of the data"
      ],
      "metadata": {
        "id": "M0QG17t6ukO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fish['Year'].value_counts()"
      ],
      "metadata": {
        "id": "jVOzO5bsw5K-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = fish.loc[fish['Year'] < 2009]\n",
        "test_set = fish.loc[fish['Year'] >= 2009]"
      ],
      "metadata": {
        "id": "T2nxm_ekxIwL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array(fish['CPUE'])\n",
        "X = np.array(fish[['Year','SST_cvW', 'SST_cvW5', 'SST_cvW4','SST_cvW3','SST_cvW2','SST_cvW1']])"
      ],
      "metadata": {
        "id": "LuU-6BO8ssBo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### One-hot encoding of categorical variables"
      ],
      "metadata": {
        "id": "1KG1Wh8Jsu0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categorical_columns = fish.select_dtypes(include=['object']).columns.tolist()\n",
        "ohe = OneHotEncoder(drop='first')\n",
        "X_ohe = ohe.fit_transform(fish[categorical_columns]).toarray()\n",
        "X_ohe"
      ],
      "metadata": {
        "id": "qB2yOc_cs1gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.concatenate((X, X_ohe), axis=1)\n",
        "X.shape"
      ],
      "metadata": {
        "id": "fKWJg32Xs-CF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}